{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "57c9d3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "7c4ae84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we skip first two row and start from 3/2/18 since directionality start at that time\n",
    "df1 = pd.read_csv('1.gt_bitcoin.csv', usecols=[2], skiprows=2, names=['1.gt_bitcoin'])\n",
    "df2 = pd.read_csv('2.gt_Buy_Bitcoin.csv', usecols=[2], skiprows=2, names=['2.gt_Buy_Bitcoin'])\n",
    "df3 = pd.read_csv('3.gt_Sell_Bitcoin.csv', usecols=[2], skiprows=2, names=['3.gt_Sell_Bitcoin'])\n",
    "df4 = pd.read_csv('4.gt_ethereum.csv', usecols=[2], skiprows=2, names=['4.gt_ethereum'])\n",
    "df5 = pd.read_csv('5.gt_Ukraine_war.csv', usecols=[2], skiprows=2, names=['5.gt_Ukraine_war'])\n",
    "df6 = pd.read_csv('6.gt_covid.csv', usecols=[2], skiprows=2, names=['6.gt_covid'])\n",
    "df7 = pd.read_csv('7.s&p_twitter.csv', usecols=[2], skiprows=2, names=['7.s&p_twitter'])\n",
    "df8 = pd.read_csv('8.CBDC_uncertainty.csv', usecols=[2], skiprows=2, names=['8.CBDC_uncertainty'])\n",
    "df9 = pd.read_csv('9.CBDC_atten.csv', usecols=[2], skiprows=2, names=['9.CBDC_atten'])\n",
    "df10 = pd.read_csv('10.news_senti.csv', usecols=[2], skiprows=2, names=['10.news_senti'])\n",
    "df11 = pd.read_csv('11.fear&greed.csv', usecols=[2], skiprows=2, names=['11.fear&greed'])\n",
    "df12 = pd.read_csv('12.tweets_pos.csv', usecols=[2], skiprows=2, names=['12.tweets_pos'])\n",
    "df13 = pd.read_csv('13.tweets_neg.csv', usecols=[2], skiprows=2, names=['13.tweets_neg'])\n",
    "df14 = pd.read_csv('14.twitter_btccrash_pos.csv', usecols=[2], skiprows=2, names=['14.twitter_btccrash_pos'])\n",
    "df15 = pd.read_csv('15.twitter_btccrash_neg.csv', usecols=[2], skiprows=2, names=['15.twitter_btccrash_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d6471af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.gt_bitcoin</th>\n",
       "      <th>4.gt_ethereum</th>\n",
       "      <th>5.gt_Ukraine_war</th>\n",
       "      <th>6.gt_covid</th>\n",
       "      <th>7.s&amp;p_twitter</th>\n",
       "      <th>9.CBDC_atten</th>\n",
       "      <th>10.news_senti</th>\n",
       "      <th>11.fear&amp;greed</th>\n",
       "      <th>12.tweets_pos</th>\n",
       "      <th>13.tweets_neg</th>\n",
       "      <th>14.twitter_btccrash_pos</th>\n",
       "      <th>15.twitter_btccrash_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004854</td>\n",
       "      <td>-0.011494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>-0.095687</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>-0.113559</td>\n",
       "      <td>0.514869</td>\n",
       "      <td>-0.138386</td>\n",
       "      <td>0.120306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004878</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.097991</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.036830</td>\n",
       "      <td>-0.234322</td>\n",
       "      <td>-0.265998</td>\n",
       "      <td>0.381993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004902</td>\n",
       "      <td>-0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.078837</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0.063410</td>\n",
       "      <td>0.100377</td>\n",
       "      <td>0.194764</td>\n",
       "      <td>-0.005493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019704</td>\n",
       "      <td>-0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.079216</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.097288</td>\n",
       "      <td>-0.182443</td>\n",
       "      <td>-0.223062</td>\n",
       "      <td>-0.145083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019324</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.051206</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>-0.214515</td>\n",
       "      <td>0.211336</td>\n",
       "      <td>0.090925</td>\n",
       "      <td>0.367505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>-0.015873</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.011905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>-0.202782</td>\n",
       "      <td>-0.034483</td>\n",
       "      <td>-0.192200</td>\n",
       "      <td>0.144226</td>\n",
       "      <td>-0.319385</td>\n",
       "      <td>-0.168254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>-0.016129</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.000638</td>\n",
       "      <td>-0.011448</td>\n",
       "      <td>-0.035714</td>\n",
       "      <td>0.172758</td>\n",
       "      <td>0.098971</td>\n",
       "      <td>-0.287368</td>\n",
       "      <td>0.329540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010970</td>\n",
       "      <td>-0.000638</td>\n",
       "      <td>-0.103914</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>-0.127630</td>\n",
       "      <td>0.026982</td>\n",
       "      <td>-0.067539</td>\n",
       "      <td>0.101123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.012346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013389</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>-0.064228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165572</td>\n",
       "      <td>-0.055837</td>\n",
       "      <td>0.233303</td>\n",
       "      <td>-0.110677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>-0.016949</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004210</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>-0.010292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.078863</td>\n",
       "      <td>-0.085177</td>\n",
       "      <td>-0.227003</td>\n",
       "      <td>-0.014420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1765 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1.gt_bitcoin  4.gt_ethereum  5.gt_Ukraine_war  6.gt_covid  \\\n",
       "0        -0.004854      -0.011494          0.000000         0.0   \n",
       "1        -0.004878      -0.011628          0.000000         0.0   \n",
       "2        -0.004902      -0.011765          0.000000         0.0   \n",
       "3         0.019704      -0.011905          0.000000         0.0   \n",
       "4         0.019324      -0.012048          0.000000         0.0   \n",
       "...            ...            ...               ...         ...   \n",
       "1760     -0.015873       0.142857         -0.011905         0.0   \n",
       "1761     -0.016129       0.125000         -0.012048         0.0   \n",
       "1762     -0.016393       0.111111         -0.012195         0.0   \n",
       "1763     -0.016667       0.100000         -0.012346         0.0   \n",
       "1764     -0.016949       0.090909         -0.012500         0.0   \n",
       "\n",
       "      7.s&p_twitter  9.CBDC_atten  10.news_senti  11.fear&greed  \\\n",
       "0          0.006039      0.000321      -0.095687       0.236842   \n",
       "1          0.003468     -0.000248      -0.097991       0.191489   \n",
       "2          0.003456     -0.000248      -0.078837      -0.214286   \n",
       "3          0.003445     -0.000248      -0.079216       0.250000   \n",
       "4          0.001584     -0.000248      -0.051206       0.072727   \n",
       "...             ...           ...            ...            ...   \n",
       "1760       0.000146     -0.000637      -0.202782      -0.034483   \n",
       "1761       0.000146     -0.000638      -0.011448      -0.035714   \n",
       "1762      -0.010970     -0.000638      -0.103914       0.037037   \n",
       "1763       0.013389     -0.000639      -0.064228       0.000000   \n",
       "1764      -0.004210     -0.000639      -0.010292       0.000000   \n",
       "\n",
       "      12.tweets_pos  13.tweets_neg  14.twitter_btccrash_pos  \\\n",
       "0         -0.113559       0.514869                -0.138386   \n",
       "1          0.036830      -0.234322                -0.265998   \n",
       "2          0.063410       0.100377                 0.194764   \n",
       "3         -0.097288      -0.182443                -0.223062   \n",
       "4         -0.214515       0.211336                 0.090925   \n",
       "...             ...            ...                      ...   \n",
       "1760      -0.192200       0.144226                -0.319385   \n",
       "1761       0.172758       0.098971                -0.287368   \n",
       "1762      -0.127630       0.026982                -0.067539   \n",
       "1763       0.165572      -0.055837                 0.233303   \n",
       "1764      -0.078863      -0.085177                -0.227003   \n",
       "\n",
       "      15.twitter_btccrash_neg  \n",
       "0                    0.120306  \n",
       "1                    0.381993  \n",
       "2                   -0.005493  \n",
       "3                   -0.145083  \n",
       "4                    0.367505  \n",
       "...                       ...  \n",
       "1760                -0.168254  \n",
       "1761                 0.329540  \n",
       "1762                 0.101123  \n",
       "1763                -0.110677  \n",
       "1764                -0.014420  \n",
       "\n",
       "[1765 rows x 12 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15], axis=1)\n",
    "df_remove = df_concat.drop(['2.gt_Buy_Bitcoin', '3.gt_Sell_Bitcoin', '8.CBDC_uncertainty'], axis=1)\n",
    "# replace \"inf\" with NaN\n",
    "df_remove = df_remove.replace('inf', 0)\n",
    "df_remove = df_remove.replace([np.inf, -np.inf], 0)\n",
    "df_na = df_remove.fillna(0)\n",
    "df_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "e7d0bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin = pd.read_csv('bitcoin.csv', usecols=[5], skiprows=2, names=['bitcoin'])\n",
    "ether = pd.read_csv('ethereum.csv', usecols=[5], skiprows=2, names=['ether'])\n",
    "BDM_exlarge = pd.read_csv('SP_BDM_exlarge.csv', usecols=[5], skiprows=2, names=['BDM_exlarge'])\n",
    "BDM = pd.read_csv('SP_BDM.csv', usecols=[5], skiprows=2, names=['BDM'])\n",
    "bitVolumn = pd.read_csv('bitcoin volumn.csv', usecols=[1], names=['bitcoinVolumn'])\n",
    "bitVolumn = bitVolumn['bitcoinVolumn'].pct_change()\n",
    "bitVolumnpct= bitVolumn.drop([0], axis=0)\n",
    "bitVolumnpct = bitVolumnpct.reset_index(drop=True)\n",
    "sp500 = pd.read_csv('SP500.csv', usecols=[1], names=['sp500'])\n",
    "sp500 = sp500['sp500'].pct_change()\n",
    "sp500pct= sp500.drop([0], axis=0)\n",
    "sp500pct = sp500pct.reset_index(drop=True)\n",
    "df_control = pd.concat([df_na,bitVolumnpct,sp500pct], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b280e",
   "metadata": {},
   "source": [
    "# 1. Bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "791c1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_concat = pd.concat([bitcoin,df_na], axis=1)\n",
    "train, test = train_test_split(bitcoin_concat, test_size = 0.3)\n",
    "x_train = train.iloc[0:,1:13]\n",
    "y_train = train.iloc[0:,0]\n",
    "x_test = test.iloc[0:,1:13]\n",
    "y_test = test.iloc[0:,0]\n",
    "scaler = StandardScaler()\n",
    "# scale the data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "4a3ef031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.530188679245283\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "logistic_acc = model.score(x_test,actuals)\n",
    "print(logistic_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e94d0b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.5659919028340081\n",
      "Accuracy: 0.5377358490566038\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "param_grid = [{'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "                 'penalty': ['l2'],\n",
    "                 'C': [0.01, 0.001, 0.5, 10]},\n",
    "                {'solver': ['saga'],\n",
    "                 'penalty': ['l1', 'l2'],\n",
    "                 'C': [0.1, 0.01, 0.001, 0.5]}\n",
    "                ]\n",
    "\n",
    "# Use Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the testing set\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred = best_lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "400c8b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112, 135],\n",
       "       [110, 173]])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46afc2d2",
   "metadata": {},
   "source": [
    "## control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f002785d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5660377358490566\n"
     ]
    }
   ],
   "source": [
    "bitcoin_control = pd.concat([bitcoin,df_control], axis=1)\n",
    "train, test = train_test_split(bitcoin_control, test_size = 0.3)\n",
    "x_train = train.iloc[0:,1:15]\n",
    "y_train = train.iloc[0:,0]\n",
    "x_test = test.iloc[0:,1:15]\n",
    "y_test = test.iloc[0:,0]\n",
    "scaler = StandardScaler()\n",
    "# scale the data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "logistic_acc = model.score(x_test,actuals)\n",
    "print(logistic_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "f3a7c1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.5862348178137651\n",
      "Accuracy: 0.5679245283018868\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "param_grid = [{'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "                 'penalty': ['l2'],\n",
    "                 'C': [0.01, 0.001, 0.5, 10]},\n",
    "                {'solver': ['saga'],\n",
    "                 'penalty': ['l1', 'l2'],\n",
    "                 'C': [0.1, 0.01, 0.001, 0.5]}\n",
    "                ]\n",
    "\n",
    "# Use Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the testing set\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred = best_lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ba73eeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[131, 116],\n",
       "       [113, 170]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b187ffeb",
   "metadata": {},
   "source": [
    "# 2. Ether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e82a0c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590566037735849\n"
     ]
    }
   ],
   "source": [
    "ether_concat = pd.concat([ether,df_na], axis=1)\n",
    "train, test = train_test_split(ether_concat, test_size = 0.3)\n",
    "x_train = train.iloc[0:,1:13]\n",
    "y_train = train.iloc[0:,0]\n",
    "x_test = test.iloc[0:,1:13]\n",
    "y_test = test.iloc[0:,0]\n",
    "scaler = StandardScaler()\n",
    "# scale the data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "logistic_acc = model.score(x_test,actuals)\n",
    "print(logistic_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "cbd17398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.5740890688259108\n",
      "Accuracy: 0.5849056603773585\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "param_grid = [{'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "                 'penalty': ['l2'],\n",
    "                 'C': [0.1, 0.01, 0.001, 0.5]},\n",
    "                {'solver': ['saga'],\n",
    "                 'penalty': ['l1', 'l2'],\n",
    "                 'C': [0.1, 0.01, 0.001, 0.5]}\n",
    "                ]\n",
    "\n",
    "# Use Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5,error_score='raise')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the testing set\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred = best_lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "70529d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127, 129],\n",
       "       [ 91, 183]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f07944",
   "metadata": {},
   "source": [
    "## control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2349868c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5509433962264151\n"
     ]
    }
   ],
   "source": [
    "ether_control = pd.concat([ether,df_control], axis=1)\n",
    "train, test = train_test_split(ether_control, test_size = 0.3)\n",
    "x_train = train.iloc[0:,1:15]\n",
    "y_train = train.iloc[0:,0]\n",
    "x_test = test.iloc[0:,1:15]\n",
    "y_test = test.iloc[0:,0]\n",
    "scaler = StandardScaler()\n",
    "# scale the data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "logistic_acc = model.score(x_test,actuals)\n",
    "print(logistic_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "b3d4ef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.5748987854251012\n",
      "Accuracy: 0.5490566037735849\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "param_grid = [{'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "                 'penalty': ['l2'],\n",
    "                 'C': np.logspace(-4, 4, 9)},\n",
    "                {'solver': ['saga'],\n",
    "                 'penalty': ['l1', 'l2'],\n",
    "                 'C': [0.1, 0.01, 0.001, 0.5]}\n",
    "                ]\n",
    "\n",
    "# Use Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the testing set\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred = best_lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "74ec3aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130, 117],\n",
       "       [122, 161]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e6036",
   "metadata": {},
   "source": [
    "# 3. BDM_exlarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "194f90d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5924528301886792\n"
     ]
    }
   ],
   "source": [
    "BDM_exlarge_concat = pd.concat([BDM_exlarge,df_na], axis=1)\n",
    "train, test = train_test_split(BDM_exlarge_concat, test_size = 0.3)\n",
    "x_train = train.iloc[0:,1:13]\n",
    "y_train = train.iloc[0:,0]\n",
    "x_test = test.iloc[0:,1:13]\n",
    "y_test = test.iloc[0:,0]\n",
    "scaler = StandardScaler()\n",
    "# scale the data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "logistic_acc = model.score(x_test,actuals)\n",
    "print(logistic_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "268f88e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.5846153846153845\n",
      "Accuracy: 0.5981132075471698\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "param_grid = [{'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "                 'penalty': ['l2'],\n",
    "                 'C': [0.1, 0.01, 0.001]},\n",
    "                {'solver': ['saga'],\n",
    "                 'penalty': ['l1', 'l2'],\n",
    "                 'C': [0.1, 0.01, 0.001]}\n",
    "                ]\n",
    "\n",
    "# Use Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the testing set\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred = best_lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "2f83e0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102, 122],\n",
       "       [ 91, 215]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ca022",
   "metadata": {},
   "source": [
    "## control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "4cccecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5924528301886792\n"
     ]
    }
   ],
   "source": [
    "BDM_exlarge_control = pd.concat([BDM_exlarge,df_control], axis=1)\n",
    "train, test = train_test_split(BDM_exlarge_control, test_size = 0.3)\n",
    "x_train = train.iloc[0:,1:15]\n",
    "y_train = train.iloc[0:,0]\n",
    "x_test = test.iloc[0:,1:15]\n",
    "y_test = test.iloc[0:,0]\n",
    "scaler = StandardScaler()\n",
    "# scale the data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "logistic_acc = model.score(x_test,actuals)\n",
    "print(logistic_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "c9f17295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.6040485829959514\n",
      "Accuracy: 0.5735849056603773\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "param_grid = [{'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "                 'penalty': ['l2'],\n",
    "                 'C': np.logspace(-4, 4, 9)},\n",
    "                {'solver': ['saga'],\n",
    "                 'penalty': ['l1', 'l2'],\n",
    "                 'C': [0.1, 0.01, 0.001, 0.5]}\n",
    "                ]\n",
    "\n",
    "# Use Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the testing set\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred = best_lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "ff2ee563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 78, 164],\n",
       "       [ 62, 226]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76530245",
   "metadata": {},
   "source": [
    "# 4. BDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "978d9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5792452830188679\n"
     ]
    }
   ],
   "source": [
    "BDM_concat = pd.concat([BDM,df_na], axis=1)\n",
    "train, test = train_test_split(BDM_concat, test_size = 0.3)\n",
    "x_train = train.iloc[0:,1:13]\n",
    "y_train = train.iloc[0:,0]\n",
    "x_test = test.iloc[0:,1:13]\n",
    "y_test = test.iloc[0:,0]\n",
    "scaler = StandardScaler()\n",
    "# scale the data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "logistic_acc = model.score(x_test,actuals)\n",
    "print(logistic_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "5a33c593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.6105263157894736\n",
      "Accuracy: 0.5754716981132075\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "param_grid = [{'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "                 'penalty': ['l2'],\n",
    "                 'C': [0.1, 0.01, 0.001]},\n",
    "                {'solver': ['saga'],\n",
    "                 'penalty': ['l1', 'l2'],\n",
    "                 'C': [0.1, 0.01, 0.001]}\n",
    "                ]\n",
    "\n",
    "# Use Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the testing set\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred = best_lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "e5b43098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93, 165],\n",
       "       [ 60, 212]])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d71477",
   "metadata": {},
   "source": [
    "## control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "b675be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590566037735849\n"
     ]
    }
   ],
   "source": [
    "BDM_control = pd.concat([BDM,df_control], axis=1)\n",
    "train, test = train_test_split(BDM_control, test_size = 0.3)\n",
    "x_train = train.iloc[0:,1:15]\n",
    "y_train = train.iloc[0:,0]\n",
    "x_test = test.iloc[0:,1:15]\n",
    "y_test = test.iloc[0:,0]\n",
    "scaler = StandardScaler()\n",
    "# scale the data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "logistic_acc = model.score(x_test,actuals)\n",
    "print(logistic_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "845dc17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.6153846153846154\n",
      "Accuracy: 0.5886792452830188\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "param_grid = [{'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "                 'penalty': ['l2'],\n",
    "                 'C': np.logspace(-4, 4, 9)},\n",
    "                {'solver': ['saga'],\n",
    "                 'penalty': ['l1', 'l2'],\n",
    "                 'C': [0.1, 0.01, 0.001, 0.5]}\n",
    "                ]\n",
    "\n",
    "# Use Grid Search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the testing set\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred = best_lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "13968ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 156],\n",
       "       [ 62, 212]])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2dac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
